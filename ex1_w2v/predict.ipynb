{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장을 입력하시오: IMF 몇년전부터 땡삼이 정부가 금융개혁법 만들어서 경제 전반 손보려는거 대선에 눈먼 김대중이랑 국민회의 애들이 보이콧해서 법안 통과 좌절되고, 그래서 IMF 온거는 영화에 다뤘겠지? 그리고 97년 대선에 IMF 경제파탄 심판론으로 당선되자마자 땡삼이가 만든 금융개혁법 그대로 가져와서 개혁하고 IMF 조기졸업한거 그 내용도 다뤘겠지? IMF는 국가 파탄내고 민심 분노 유발해서 그걸로 정권 장악하고자 하는 민주진포팔이들 작품인데 이걸로 또 무슨 선동을 하려고?\n",
      "\n",
      "#######################################Matched####################################\n",
      "{'(\"\\'\", \\'Punctuation\\')',\n",
      " '(\"\\',\", \\'Punctuation\\')',\n",
      " '(\"\\']\", \\'Punctuation\\')',\n",
      " '(\"[\\'\", \\'Punctuation\\')',\n",
      " \"('가', 'Josa')\",\n",
      " \"('가져오다', 'Verb')\",\n",
      " \"('개혁', 'Noun')\",\n",
      " \"('거', 'Noun')\",\n",
      " \"('것', 'Noun')\",\n",
      " \"('경제', 'Noun')\",\n",
      " \"('국가', 'Noun')\",\n",
      " \"('그', 'Noun')\",\n",
      " \"('그것', 'Noun')\",\n",
      " \"('그대로', 'Noun')\",\n",
      " \"('그래서', 'Adverb')\",\n",
      " \"('그리고', 'Conjunction')\",\n",
      " \"('금융', 'Noun')\",\n",
      " \"('내다', 'Verb')\",\n",
      " \"('내용', 'Noun')\",\n",
      " \"('눈', 'Noun')\",\n",
      " \"('늘다', 'Verb')\",\n",
      " \"('다루다', 'Verb')\",\n",
      " \"('대선', 'Noun')\",\n",
      " \"('도', 'Josa')\",\n",
      " \"('되다', 'Verb')\",\n",
      " \"('들', 'Suffix')\",\n",
      " \"('땡', 'Noun')\",\n",
      " \"('또', 'Noun')\",\n",
      " \"('론', 'Noun')\",\n",
      " \"('만들다', 'Verb')\",\n",
      " \"('멀다', 'Adjective')\",\n",
      " \"('무슨', 'Noun')\",\n",
      " \"('법', 'Noun')\",\n",
      " \"('보다', 'Verb')\",\n",
      " \"('보이콧', 'Noun')\",\n",
      " \"('부터', 'Josa')\",\n",
      " \"('분노', 'Noun')\",\n",
      " \"('선동', 'Noun')\",\n",
      " \"('손', 'Noun')\",\n",
      " \"('심판', 'Noun')\",\n",
      " \"('애', 'Noun')\",\n",
      " \"('에', 'Josa')\",\n",
      " \"('영화', 'Noun')\",\n",
      " \"('오다', 'Verb')\",\n",
      " \"('유발', 'Noun')\",\n",
      " \"('으로', 'Josa')\",\n",
      " \"('을', 'Josa')\",\n",
      " \"('의', 'Josa')\",\n",
      " \"('이', 'Determiner')\",\n",
      " \"('이', 'Josa')\",\n",
      " \"('인데', 'Josa')\",\n",
      " \"('작품', 'Noun')\",\n",
      " \"('전반', 'Noun')\",\n",
      " \"('정권', 'Noun')\",\n",
      " \"('정부', 'Noun')\",\n",
      " \"('좌절', 'Noun')\",\n",
      " \"('통과', 'Noun')\",\n",
      " \"('팔이', 'Noun')\",\n",
      " \"('하고', 'Josa')\",\n",
      " \"('하다', 'Verb')\",\n",
      " \"('한', 'Determiner')\"}\n",
      "#######################################Unmatched##################################\n",
      "{\"('97년', 'Number')\",\n",
      " \"('IMF', 'Alpha')\",\n",
      " \"('국민회', 'Noun')\",\n",
      " \"('김대중', 'Noun')\",\n",
      " \"('년전', 'Noun')\",\n",
      " \"('당선', 'Noun')\",\n",
      " \"('몇', 'Modifier')\",\n",
      " \"('민심', 'Noun')\",\n",
      " \"('민주', 'Noun')\",\n",
      " \"('법안', 'Noun')\",\n",
      " \"('삼이', 'Noun')\",\n",
      " \"('이랑', 'Josa')\",\n",
      " \"('장악', 'Noun')\",\n",
      " \"('조기졸업', 'Noun')\",\n",
      " \"('진포', 'Noun')\",\n",
      " \"('파탄', 'Noun')\"}\n",
      "###################################################################################\n",
      "Index_list(input)[[22397 23926 18340 11785 23926 23926  5711 18340 11785  1461 23926 18340\n",
      "  11785 18499 19580 18340 11785 21997 17349 20464 18340 11785   547 18340\n",
      "  11785  6093 18340 11785 16846 18340 11785 22804   721 18340 11785  4973\n",
      "  13071 18340 11785 23145  3865 18340 11785 23926 23926 18340 11785 23926\n",
      "   1879 18340 11785 14886 15097  3694 18340 11785 21353 12897 18340 11785\n",
      "  23926 18340 11785 11670 18340 11785 18464  5705 18340 11785 15164 18340\n",
      "  11785 23926 18340 11785  1579 18340 11785 14485 13071 18340 11785 15445\n",
      "  18340 11785 15237 18340 11785 23926 18340 11785  4973 13071 18340 11785\n",
      "  23926 18340 11785  6093]]\n",
      "\n",
      "\n",
      "Output:\n",
      "'분노'가44.86% 발현되었습니다.\n",
      "'혐오'가42.96% 발현되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from konlpy.tag import Okt as Twitter\n",
    "import re\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "\n",
    "# token2index에서는 '0'외에는 token들로 구성되어 있으며, index2vector값에서는 각 token들 index와, '0'의 index값과 마지막 index로 np.zeros(300)이 들어있다. \n",
    "class Predict():\n",
    "    \n",
    "    def __init__(self, sent=\"나는 오늘 화가 많이 났다.\"):\n",
    "            # 1.데이터 준비하기\n",
    "            self.sentence = sent\n",
    "            # 2. 모델 불러오기\n",
    "            json_file = open('model.json','r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            self.model = model_from_json(loaded_model_json)\n",
    "            self.model.load_weights('Attention_weight.h5')\n",
    "            #이거 필요없을것 같은데\n",
    "            self.index2vec = np.fromfile('index2vec.dat',dtype='float32')\n",
    "#             self.index2vec = np.fromfile('index2vec.dat')\n",
    "            self.max_sentence = 100\n",
    "            #\"토큰당 인덱스가 들어있는파일\"\n",
    "            with open('token2index.json','r') as dictionary_file:\n",
    "                self.token2index = json.load(dictionary_file)\n",
    "                \n",
    "    def tokenizer(self):\n",
    "        token = []\n",
    "        twitter = Twitter()\n",
    "        self.sentence = re.sub(r\"[^ㄱ-힣a-zA-Z0-9]+\", ' ', self.sentence).strip().split()\n",
    "        \n",
    "        token.extend(twitter.pos(str(self.sentence), norm=True, stem=True))\n",
    "\n",
    "#         print(type(token))\n",
    "        return token\n",
    "    \n",
    "    def t2index(self, t_list):\n",
    "        index_list = []\n",
    "        match = set()\n",
    "        unmatch = set()\n",
    "        for token in t_list:\n",
    "            if str(token).replace(\" \", \"\") in self.token2index:\n",
    "                match.add(str(token))\n",
    "                index_list.append(self.token2index[str(token).replace(\" \", \"\")])\n",
    "            else:\n",
    "                unmatch.add(str(token))\n",
    "                index_list.append(self.token2index['0'])\n",
    "                \n",
    "                \n",
    "        print(\"#######################################Matched####################################\")\n",
    "        pprint.pprint(match)\n",
    "        print(\"#######################################Unmatched##################################\")\n",
    "        pprint.pprint(unmatch)\n",
    "        print(\"###################################################################################\")\n",
    "        \n",
    "        #padding\n",
    "        if(len(index_list)> self.max_sentence):\n",
    "            return index_list[0:100]\n",
    "        else:\n",
    "            #token2index의key길이==zero가 있는 index이다. index2vec의 마지막 index와 len(token2index)같으면 된다. \n",
    "            #-1 지금 붙여논 상황\n",
    "            index_list.extend([len(self.token2index)-1]*(self.max_sentence-len(index_list)))\n",
    "#         100개의 index 토큰으로 분류된 문장 return\n",
    "            return index_list\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sentence = input(\"문장을 입력하시오: \")\n",
    "    print(\"\")\n",
    "    predict = Predict(sentence)\n",
    "    tok = predict.tokenizer()\n",
    "    #토큰화 시킨 후 토큰화 된 단어를 token2index에 넣을떄, ()의 공백을 없애주어야 한다.\n",
    "    #1.  in word_tmp_dict\n",
    "    #2. 또한 x_test의 데이터타입과 token2index의 key데이터 타입이 같은지 확인해 주어야한다.\n",
    "    # for i in token2index.keys(): print(type(i)), tuple(x_test) or str(x_test)\n",
    "    x_test = predict.t2index(tok)\n",
    "    #3. token2index파트에서, 전해진 tok 데이터 타입이 int가 되도록 해주어, index2vec의 index데이터 타입과 같도록 만들어준다. \n",
    "    #4. 넘파이화 시켜주어서, 이후 plot 찍어줄수 있도록한다.\n",
    "    x_test = np.asarray([x_test])\n",
    "    print(\"Index_list(input)\"+str(x_test))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "#     print(x_test.shape)\n",
    "#     # 3. 모델 사용하기\n",
    "#     #5. yhat이 [0.4,0.8,0.9.....]이런식으로 나오는데, threshold(0.5)를 넘기면 모두 1이 되도록 만들어주고 그게 아니면 0이되도록 변환시켜준다.\n",
    "#     yhat = predict.model.predict(x_test,batch_size=1)\n",
    "    yhat = predict.model.predict(x_test)\n",
    "    yhat = yhat[0]\n",
    "#     print(len(yhat))\n",
    "    #yhat중 1인 녀석 index를 뽑아낸다.\n",
    "    columns = [\"분노\",\"기대\",\"혐오\",\"두려움\",\"기쁨\",\"사랑\",\"낙관\",\"비관\",\"슬픔\",\"놀라움\",\"믿음\"]\n",
    "    y_index = list()\n",
    "    for i,e in enumerate(yhat):\n",
    "        y_index = [i for i, e in enumerate(yhat) if e > 0.32]\n",
    "    print(\"Output:\")\n",
    "    for i in y_index:\n",
    "        print(\"'{0}'가{1:.2f}% 발현되었습니다.\".format(str(columns[i]),(yhat[i])*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
