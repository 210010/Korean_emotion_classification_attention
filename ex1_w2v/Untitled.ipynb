{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_array(6651, 13)\n",
      "val_array(887, 13)\n",
      "test_array(3239, 13)\n",
      "Reading data!\n",
      "checking Anomaly!!\n",
      "(6619,)\n",
      "(6619, 11)\n",
      "(883,)\n",
      "(883, 11)\n",
      "(3215,)\n",
      "(3215, 11)\n",
      "ANomaly result!\n",
      "x_train.shape(6619,)\n",
      "y_train.shape(6619, 11)\n",
      "x_val.shape(883,)\n",
      "y_val.shape(883, 11)\n",
      "x_test.shape(3215,)\n",
      "y_test.shape(3215, 11)\n",
      "Finished!\n",
      "Tokenizing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "589it [00:00, 5885.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing finished!\n",
      "It's by len()\n",
      "train_tmp.len():6619,40\n",
      "val_tmp shape.len():883,39\n",
      "test_tmp shape.len():3215,46\n",
      "max_count:10531\n",
      "Readding Embedding file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45942it [00:05, 8058.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45942 word vectors.\n",
      "word_vec shape:6619,100\n",
      "word_vec_val shape:883,100\n",
      "word_vec_test shape:3215,100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, re, csv, math, codecs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer as t\n",
    "from tqdm import tqdm\n",
    "from keras.layers import merge, Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import *\n",
    "# to visualize, and to make zero shape matrix\n",
    "from attention_utils import get_activations, get_data_recurrent\n",
    "from Attention import Attention\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt as Twitter\n",
    "from selfword2vec import tokenization\n",
    "from Anomaly import checkAnomaly_x_y\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from numpy import argmax\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# 1. 모델 저장시키기 \n",
    "# 2. tokenizer와 konlpy morphs 호환 여부 (완성 jupyter note)\n",
    "# 2'. word2vec 2가지 경우 더 추가 to embedding(final_total word2vec, twitter_translated.vec)\n",
    "# 3. 변수들 설정하기\n",
    "\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# NUM_WORDS, train으로 input받은 단어의 수\n",
    "MAX_NB_WORDS = 20000\n",
    "vocab_size = 0\n",
    "EMB_DIM = 300\n",
    "embeddings_index = dict()\n",
    "\n",
    "# columns = [\"ID\", \"Tweet\", \"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"love\", \"optimism\", \"pessimism\",\"sadness\",\"surprise\",\"trust\"]\n",
    "columns = [\"ID\",\"Tweet\",\"분노\",\"기대\",\"혐오스러운\",\"두려움\",\"기쁨\",\"사랑\",\"낙관론\",\"비관론\",\"슬픔\",\"놀라움\",\"믿음\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################1. 데이터셋 생성하기\n",
    "\n",
    "train_array = pd.read_csv(\"/home/minwookje/coding/ex1_w2v/data/tweet/dump/kor_train.txt\",sep=\"\\t\", header=None,names=columns).values\n",
    "val_array = pd.read_csv(\"/home/minwookje/coding/ex1_w2v/data/tweet/dump/kor_dev.txt\",sep=\"\\t\", header=None,names=columns).values\n",
    "test_array = pd.read_csv(\"/home/minwookje/coding/ex1_w2v/data/tweet/dump/kor_test_gold.txt\",sep=\"\\t\", header=None,names=columns).values\n",
    "\n",
    "# 판다 shape\n",
    "print(\"train_array\"+ str(train_array.shape))\n",
    "print(\"val_array\"+str(val_array.shape))\n",
    "print(\"test_array\"+str(test_array.shape))\n",
    "\n",
    "print(\"Reading data!\")\n",
    "#  x, y 분할하기\n",
    "x_train = train_array[1:,1]\n",
    "y_train = train_array[1:,2:]\n",
    "x_val = val_array[1:,1]\n",
    "y_val = val_array[1:,2:]\n",
    "x_test = test_array[1:,1]\n",
    "y_test = test_array[1:,2:]\n",
    "\n",
    "\n",
    "print(\"checking Anomaly!!\")\n",
    "x_train, y_train = checkAnomaly_x_y(x_train,y_train)\n",
    "x_val, y_val = checkAnomaly_x_y(x_val,y_val)\n",
    "x_test, y_test = checkAnomaly_x_y(x_test,y_test)\n",
    "\n",
    "print(\"ANomaly result!\")\n",
    "print(\"x_train.shape\"+ str(x_train.shape))\n",
    "print(\"y_train.shape\"+ str(y_train.shape))\n",
    "print(\"x_val.shape\"+ str(x_val.shape))\n",
    "print(\"y_val.shape\"+ str(y_val.shape))\n",
    "print(\"x_test.shape\"+ str(x_test.shape))\n",
    "print(\"y_test.shape\"+ str(y_test.shape))\n",
    "# print(type(x_train)) np.array로 변형이 필요한가\n",
    "print(\"Finished!\")\n",
    "\n",
    "# jupyter notebook\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "tmp = []\n",
    "train_tmp = []\n",
    "val_tmp = []\n",
    "test_tmp = []\n",
    "max_count = 0\n",
    "set_words = set()\n",
    "\n",
    "print(\"Tokenizing!\")\n",
    "# test의 tmp만 따로 받아주고 나머지는 val train test모두 통합시켜준다.\n",
    "test_tmp, dummy , set_words = tokenization(x_test)\n",
    "val_tmp, dummy , set_words = tokenization(x_val)\n",
    "train_tmp, max_count , set_words = tokenization(x_train)\n",
    "tmp, dummy , set_words = tokenization(np.hstack([x_train,x_val,x_test]))\n",
    "print(\"Tokenizing finished!\")\n",
    "tmp = [] # tmp없애준다\n",
    "\n",
    "\n",
    "\n",
    "#token shape\n",
    "print(\"It's by len()\")\n",
    "print(\"train_tmp.len():\" + str(len(train_tmp))+\",\"+ str(len(train_tmp[0])))\n",
    "print(\"val_tmp shape.len():\" + str(len(val_tmp))+\",\"+ str(len(val_tmp[0])))\n",
    "print(\"test_tmp shape.len():\" + str(len(test_tmp))+\",\"+ str(len(test_tmp[0])))\n",
    "\n",
    "\n",
    "print(\"max_count:\"+str(max_count))\n",
    "# 문장길이 100으로 맞춘다.\n",
    "max_count = min(100, max_count)\n",
    "\n",
    "\n",
    "print(\"Readding Embedding file\")\n",
    "# embeddings_index == dict(w2v's word: vector)\n",
    "f = codecs.open('/home/minwookje/coding/ex1_w2v/embedding/1542954106final_total_pos.vec', encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# word2index table 생성 {token:index}\n",
    "# 모든 train val test에 사용되는 token별 index table\n",
    "# train 문장 token 갯수\n",
    "word_index = len(set_words)\n",
    "word_tmp_dict = dict()\n",
    "for i, word in enumerate(set_words):\n",
    "    word_tmp_dict[str(word).replace(\" \", \"\")] = i\n",
    "word_tmp_dict['0'] = word_index \n",
    "\n",
    "## 문장별 토큰화시킨 녀석에 index를 집어 넣어준다. 이때 pad도 동시에 해준다. \n",
    "word_vec = []\n",
    "word_vec_test = []\n",
    "word_vec_val = []\n",
    "\n",
    "for sent in train_tmp:\n",
    "    sub = []\n",
    "    for word in sent:\n",
    "        if(len(sub)==max_count):\n",
    "            break    \n",
    "         #print(word)\n",
    "         #print(type(str(word)))\n",
    "         #break\n",
    "# word는 tuple 타입, embeddings_index는 str타입, tuple 타입을 str()화시키면 \n",
    "# 중간에 space가 생성되어 match가 되지 않았다. 이를 해결해주었다. \n",
    "        if(str(word).replace(\" \", \"\") in word_tmp_dict):\n",
    "            \n",
    "            sub.append(word_tmp_dict[str(word).replace(\" \", \"\")])\n",
    "        else:\n",
    "            print(\"sentence index화 실패\")\n",
    "    count = max_count - len(sub)\n",
    "    # padding\n",
    "    sub.extend([word_index]*count)\n",
    "    word_vec.append(sub)\n",
    "## 테스트용 복사본 \n",
    "for sent in test_tmp:\n",
    "    sub = []\n",
    "    for word in sent:\n",
    "        if(len(sub)==max_count):\n",
    "            break\n",
    "         #print(word)\n",
    "         #print(type(str(word)))\n",
    "         #break\n",
    "# word는 tuple 타입, embeddings_index는 str타입, tuple 타입을 str()화시키면 \n",
    "# 중간에 space가 생성되어 match가 되지 않았다. 이를 해결해주었다. \n",
    "        if(str(word).replace(\" \", \"\") in word_tmp_dict):\n",
    "            \n",
    "            sub.append(word_tmp_dict[str(word).replace(\" \", \"\")])\n",
    "        else:\n",
    "            print(\"sentence index화 실패\")\n",
    "    count = max_count - len(sub)\n",
    "    # padding\n",
    "    sub.extend([word_index]*count)\n",
    "    word_vec_test.append(sub)\n",
    "\n",
    "## 검증용 복사본 \n",
    "for sent in val_tmp:\n",
    "    sub = []\n",
    "    for word in sent:\n",
    "        if(len(sub)==max_count):\n",
    "            break\n",
    "         #print(word)\n",
    "         #print(type(str(word)))\n",
    "         #break\n",
    "# word는 tuple 타입, embeddings_index는 str타입, tuple 타입을 str()화시키면 \n",
    "# 중간에 space가 생성되어 match가 되지 않았다. 이를 해결해주었다. \n",
    "        if(str(word).replace(\" \", \"\") in word_tmp_dict):\n",
    "            \n",
    "            sub.append(word_tmp_dict[str(word).replace(\" \", \"\")])\n",
    "        else:\n",
    "            print(\"sentence index화 실패\")\n",
    "    count = max_count - len(sub)\n",
    "    # padding\n",
    "    sub.extend([word_index]*count)\n",
    "    word_vec_val.append(sub)\n",
    "\n",
    "print(\"word_vec shape:\" + str(len(word_vec))+\",\"+ str(len(word_vec[0])))\n",
    "print(\"word_vec_val shape:\" + str(len(word_vec_val))+\",\"+ str(len(word_vec_val[0])))\n",
    "print(\"word_vec_test shape:\" + str(len(word_vec_test))+\",\"+ str(len(word_vec_test[0])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match:11300\n",
      "unmatch:12626\n"
     ]
    }
   ],
   "source": [
    "# 4번쨰 matrix embedding_matrix {index: vector}\n",
    "# vocab_size = min(MAX_NB_WORDS, word_index)\n",
    "vocab_size = word_index\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size+1, EMB_DIM))\n",
    "match_count = 0\n",
    "unmatch_count = 0\n",
    "\n",
    "for word, i in word_tmp_dict.items():\n",
    "    if word != '0':\n",
    "        if (word in embeddings_index):\n",
    "            match_count += 1\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            unmatch_count += 1\n",
    "            embedding_matrix[i] = np.random.uniform(-0.25,0.25,300) ## used for OOV words\n",
    "\n",
    "print(\"match:\" + str(match_count))\n",
    "print(\"unmatch:\" + str(unmatch_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec = np.array(word_vec)\n",
    "word_vec_val = np.array(word_vec_val)\n",
    "word_vec_test = np.array(word_vec_test)\n",
    "embedding_matrix = np.matrix(embedding_matrix)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 300 #wordvec사이즈\n",
    "max_count = max_count #문장의 max길이\n",
    "lstm_shape = 250\n",
    "rate_drop_lstm = 0.0\n",
    "rate_drop_dense = 0.0\n",
    "\n",
    "k_vec = word_vec\n",
    "k_vec_val = word_vec_val\n",
    "k_vec_test = word_vec_test\n",
    "k_y_train = y_train\n",
    "k_y_val = y_val\n",
    "k_y_test = y_test\n",
    "k_embedding_matrix = embedding_matrix\n",
    "\n",
    "# 32하니까 죽어버린다.\n",
    "batch_size = 512\n",
    "# Define the model\n",
    "# inp = InputLayer(shape=(max_count,), dtype='float32',sparse=True)\n",
    "# input layer는 \n",
    "# inp = InputLayer(input_shape=(max_count,),sparse=True)\n",
    "\n",
    "# inp = Input(shape=(max_count,))\n",
    "inp = Input(shape=(max_count,), dtype='float32')\n",
    "emb = Embedding(input_dim=vocab_size+1, output_dim=EMB_DIM,\n",
    "            trainable=False, weights=[embedding_matrix], input_length=max_count)(inp)\n",
    "# max_features = vocab_size, maxlen=text_max_words, embed_size=EMB_DIM\n",
    "# emb = Embedding(input_dim=max_features, input_length = maxlen, output_dim=embed_size)(inp)\n",
    "# embedding dropout = 0.1\n",
    "x = SpatialDropout1D(0.1)(emb)\n",
    "x = Bidirectional(LSTM(lstm_shape,return_sequences=True, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))(emb)\n",
    "\n",
    "x, attention = Attention()(x,rate_drop_dense)\n",
    "x = Dense(11, activation=\"sigmoid\")(x)\n",
    "# x = Dense(11)(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "# accu = jaccard_distance_acc   \n",
    "# # loss = tf.nn.sigmoid_cross_entropy_with_logits\n",
    "# loss = binary_crossentropy\n",
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "# attention_model = Model(inputs=inp, outputs=attention) # Model to print out the attention data\n",
    "print(model.summary())\n",
    "# # verbose= ? , validation_split은 validation file로 변환시켜주어야 한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# STAMP = './First_AttentionNLP_%.2f_%.2f'%(rate_drop_lstm,rate_drop_dense)\n",
    "# print(STAMP)\n",
    "# early_stopping =EarlyStopping(monitor='val_loss', patience=5)\n",
    "# bst_model_path = STAMP + '.h5'\n",
    "# model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "# # model.fit(X_t, y, validation_data=(x_val,y_val), epochs=3, verbose=1, batch_size=512)\n",
    "# epoch = 50\n",
    "\n",
    "model.fit(k_vec, k_y_train, validation_data=(k_vec_val,k_y_val), epochs=1, verbose=1, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# model.fit(k_vec, k_y_train, validation_data=(k_vec_val,k_y_val), epochs=3, verbose=1, steps_per_epoch=int(6619/batch_size)+1, validation_steps = int(883/batch_size)+1)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "score, acc = model.evaluate(k_vec_test, k_y_test, batch_size=batch_size)\n",
    "print('')\n",
    "print('score : ' + str(score)+ 'acc : ' + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      "[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(k_vec_val, batch_size=batch_size, verbose=0)\n",
    "for value in result:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('tanh_mlp2').output)\n",
    "intermediate_output = intermediate_layer_model.predict(k_vec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_5:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_5:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Requested Tensor connection between nodes \"input_5\" and \"dense_4/Sigmoid\" would create a cycle.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-68d01ea2de5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m get_3rd_layer_output = K.function([model.layers[1].input],\n\u001b[1;32m      5\u001b[0m                                   [model.layers[2].output])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_3rd_layer_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \"\"\"\n\u001b[1;32m   1430\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1385\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1386\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Requested Tensor connection between nodes \"input_5\" and \"dense_4/Sigmoid\" would create a cycle."
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[1].input],\n",
    "                                  [model.layers[2].output])\n",
    "layer_output = get_3rd_layer_output([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
